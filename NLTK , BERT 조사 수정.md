Nltk 조사 - https://github.com/nltk/nltk
-NLTK (Natural Language Toolkit)는 가장 널리 알려진 고성능 파이썬 NLP 라이브러리다. 주로 영어를 기반으로 하고 있다.

- 이 라이브러리를 통해 자연어처리가 되면, 컴퓨터는 이 처리된 정보를 바탕으로 음성 인식, 내용 요약, 번역, 감성 분석, 텍스트 분류 작업을 할 수 있다. 
  -Apache 라이선스 준수하며, 텍스트를 다루기 위한 다양한 도구들을 제공한다. 분류, 토큰화, 스테밍(Stemming), 태깅, 파싱, 시멘틱 추론을 예로 들 수 있다. 
  Nltk에서 지원하는 주요 기능 – 말뭉치, 토큰 생성, 형태소 분석 등이 있다.
  말뭉치 - 자연어 분석 작업을 위해 만든 샘플 문서 집합을 말한다. 단순히 소설, 신문 등의 문서를 모아놓은 것도 있지만 품사. 형태소, 등의 보조적 의미를 추가하고 쉬운 분석을 위해 구조적인 형태로 정리해 놓은 것을 포함한다
  토큰 생성- 단어를 추출하려면, nltk.tokenize 패키지를 안에 있는 word_tokenize 함수를 활용하면 문장에 있는 단어만 추출할 수 있다. 
  형태소 분석 - 형태소 분석(morphological analysis)이란 단어로부터 어근, 접두사, 접미사, 품사 등 다양한 언어적 속성을 파악하고 이를 이용하여 형태소를 찾아내거나 처리하는 작업이다.
  한국어 토큰화 오픈소스 - https://github.com/twitter/twitter-korean-text
  이 오픈소스에서는 현재 텍스트 정규화와 형태소 분석, 스테밍을 지원하고 있습니다. 짧은 단어는 물론이고 긴 글도 처리할 수 있다. twitter-korean-text는 normalization, tokenization, stemming, phrase extraction 이렇게 네가지 기능을 지원한다.
  BERT 조사
- BERT는 구글에서 개발한 자연어처리(NLP) 훈련 기술이다. 특정 분야에 국한되지 않고 모든 자연어 처리 분야에서 좋은 성능을 내는 범용 Language Model이다. BERT는 지금까지의 자연어 처리에 활용되었던 다른 모델들보다 더 좋은 성능을 내고 있어 많은 관심을 받고 있다. 이전에는 단어 임베딩을 위해 Word2Vec, Glove, Fasttext 방식을 사용했지만, BERT가 자연어 처리 분야의 11개 실험에서 가장 좋은 성능을 차지하면서 많이 사용되고 있다. 
- BERT는 언어 표현을 사전 학습시키는 방식을 통해 사용할 수 있다. 사전 학습은 BERT가 Wikipedia와 같은 대량의 텍스트 소스로 처음 학습되는 방법을 나타낸다. 이후 학습 결과를 [질문 답변] 및 [감정 분석]과 같은 다른 자연어 처리(NLP) 태스크에 적용할 수 있다. BERT 및 AI Platform Training을 사용하면 약 30분 만에 다양한 NLP 모델을 학습시킬 수 있다.
- BERT를 이용하면 스팸메일 찾기, 문장 분류, 감성 분류,  두 문장 사이의 관계 분류, 문장 내 단어 라벨링, 자연어 추론, 개체명 인식, 텍스트 유사도 검사, 묻고 답히기, 등등이 가능하다.
- Bert가 어떻게 동작하는지 자세하게 설명하자면, 크게 3단계로 진행된다. 첫 번째로, input 이다. Bert의 input은 token,segment,position Embedding 세 가지로 이루어진다. 먼저, token은 word piece 임베딩 방식을 사용하며, 문자 단위로 임베딩 한다. Segment는 토큰 과정을 거틴 단어를 다시 하나의 문장으로 만드는 작업이다. 두 개의 문장을 구분자를 넣어 구분하고 그 두 문장을 하나의 segment로 지정하여 입력한다. Position은 토큰 순서대로 인코딩을 하는 것을 뜻한다. BERT는 위 세가지 임베딩을 합치고 이에 Layer정규화와 Dropout을 적용하여 입력으로 사용한다. 2단계는 pre-Training 이다. Bert는 사전학습을 시킨 후 사용하는 프로그램이기 때문에, 문장을 왼쪽에서 오른쪽으로 학습하여 다음 단어를 예측하는 방식을 주로 사용한다. 마지막으로, Transfer Learning 단계이다. 학습된 언어모델을 전이학습시켜 실제로 자연어처리를 진행한다. 
- 이 서비스에선 사용자에게서 받아온 키워드들을 광고 카테고리로 분류하는 방식으로 사용한다.
- NLTK와 twitter-korean-text, Bert 오픈소스 모두 Apache License 2.0 라이선스를 따르며, 상업적 사용, 복제, 배포, 수정 가능, 소스코드 공개 의무가 없다. 
