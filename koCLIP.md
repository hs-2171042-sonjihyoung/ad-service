KoCLIP은 이미지가 주어지면 샘플링된 텍스트 세트들 중 어떤 데이터 세트에서 실제로 쌍을 이루었는지 분석하여 검색된 이미지에 맞는 텍스트를 제공합니다. 
이미 인터넷에서 공개적으로 사용할 수 있는 텍스트-이미지 쌍에서 학습하기에 본래 비용과 인원을 많이 필요로 하는 사전 데이터 세트 작업과 다른점을 보입니다.

기능:
Image to Text : 제로 샷 이미지 분류 작업입니다. 입력 이미지가 주어지면 모델은 제공된 텍스트 레이블 중에서 가장 가능성이 높은 캡션을 찾습니다.
Text to Image : 이미지 검색 작업입니다. 텍스트가 주어지면 모델은 미리 계산된 이미지 임베딩의 데이터베이스를 조회하여 주어진 텍스트와 가장 일치하는 이미지를 찾습니다.

프로젝트내 기능:
사용자가 검색한 이미지에 알맞은 텍스트를 추정·분석하여 텍스트로 반환합니다.

작동순서: 
KoCLIP은 이미지 인코더와 텍스트 인코더를 사전 교육하여 데이터 세트의 어떤 텍스트와 어떤 이미지가 쌍을 이루는지 분석합니다. 그런 다음 CLIP를 제로샷 분류기로 전환합니다. 데이터 세트의 모든 클래스를 “개 사진” 같은 캡션으로 변환하고 주어진 이미지와 최상의 쌍을 추정·분석합니다.

훈련:
KoCLIP은MSCOCO2014 이미지 캡션 데이터 세트의 82,783개 이미지를 사용하여 미세 조정되었습니다. 이미지 캡션의 한국어 번역은 한국 과학기술정보통신부 산하 자회사가 관리하는 개방형 데이터베이스인AI Hub에서 가져왔습니다. 유효성 검사 메트릭은 앞서 언급한 데이터 세트의 유효성 검사 세트에서 약 40,000개의 이미지를 사용하여 모니터링되었습니다.

KoCLIP은 TPU3-v8 VM에서 훈련되었습니다. 텍스트 및 이미지 인코더 백본은 모두 미리 학습된 검사점에서 로드되었습니다. KoCLIP은 일치하는 이미지 쌍과 캡션 간의 유사성 점수를 최대화하도록 훈련되었습니다.

라이선스: Apache-2.0 license


